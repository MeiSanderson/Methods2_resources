ggplot(data.frame(x = data), aes(x)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = .2, fill = "#FF6666") +
labs(title = "Histogram of Simulated Data", x = "Value", y = "Density")
# Get empirical stuff
mean(data) # 50.0574
sd(data)   # 10.29745
# See the range of x
summary(hibbs$growth) # roughly 0 to 4%
# Let's write down what we know. We're given the linear relationship, and we know what the residual standard deviation should be:
intercept = 30
slope = 10
residual_sd = 3.9
# Now, let's generate some x-values in the same range as the real data (0 to 4 roughly), since the question asks for 'same range of x'
x_values <- seq(0, 4, length.out = 1000)  # x ranging from 0 to 4%, getting 100 points
# Now, we can calculate some y values based on the line we're given (we will add the error term shortly)
y_values_line <- intercept + slope * x_values
# Generate hypothetical data with the same residual standard deviation
# We can do this by adding normally distributed random errors with standard deviation of 3.9
set.seed(123)  # for reproducibility
y_values_data <- y_values_line + rnorm(length(x_values), mean = 0, sd = residual_sd)
# Create dataframe for ggplot
data <- data.frame(
x = x_values,            # our x-values between 0 and 4
y_line = y_values_line,  # y-data with line
y_data = y_values_data   # y-data with error
)
# Now, let's plot
p <- ggplot(data, aes(x = x)) +
geom_point(aes(y = y_data), alpha = 0.6, color = 'blue') +  # Plotting the data points
geom_line(aes(y = y_line), color = 'black') +  # Plotting the regression line
labs(
x = 'Average recent growth in personal income (%)',
y = "Incumbent party's vote share",
title = 'Hypothetical data and fitted line',
subtitle = 'Fitted line: y = 30 + 10x'
) +
theme_minimal() +
theme(legend.position = "none") +
geom_smooth(aes(y = y_data), method = "lm", se = FALSE, color = "black")  # Ensure the correct y aesthetic is used
# Display the plot
p
# Fit a model for fun to see
M12a <- stan_glm(y_data ~ x, data = data, refresh = 0)
print(M12a) # We see 3.9 under sigma indeed
set.seed(2003) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# Specifying my stuff
n <- 20 # Number of points
mean <- 50 # Specified mean
sd <- 10 # Specified standard deviation
data <- rnorm(n, mean, sd) # Generate random data
# Making a plot
ggplot(data.frame(x = data), aes(x)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = .2, fill = "#FF6666") +
labs(title = "Histogram of Simulated Data", x = "Value", y = "Density")
# See the range of x
summary(hibbs$growth) # roughly 0 to 4%
# Let's write down what we know. We're given the linear relationship, and we know what the residual standard deviation should be:
intercept = 30
slope = 10
residual_sd = 3.9
# Now, let's generate some x-values in the same range as the real data (0 to 4 roughly), since the question asks for 'same range of x'
x_values <- seq(0, 4, length.out = 20)  # x ranging from 0 to 4%, getting 100 points
# Now, we can calculate some y values based on the line we're given (we will add the error term shortly)
y_values_line <- intercept + slope * x_values
# Generate hypothetical data with the same residual standard deviation
# We can do this by adding normally distributed random errors with standard deviation of 3.9
set.seed(123)  # for reproducibility
y_values_data <- y_values_line + rnorm(length(x_values), mean = 0, sd = residual_sd)
# Create dataframe for ggplot
data <- data.frame(
x = x_values,            # our x-values between 0 and 4
y_line = y_values_line,  # y-data with line
y_data = y_values_data   # y-data with error
)
# Now, let's plot
p <- ggplot(data, aes(x = x)) +
geom_point(aes(y = y_data), alpha = 0.6, color = 'blue') +  # Plotting the data points
geom_line(aes(y = y_line), color = 'black') +  # Plotting the regression line
labs(
x = 'Average recent growth in personal income (%)',
y = "Incumbent party's vote share",
title = 'Hypothetical data and fitted line',
subtitle = 'Fitted line: y = 30 + 10x'
) +
theme_minimal() +
theme(legend.position = "none") +
geom_smooth(aes(y = y_data), method = "lm", se = FALSE, color = "black")  # Ensure the correct y aesthetic is used
# Display the plot
p
# Fit a model for fun to see
M12a <- stan_glm(y_data ~ x, data = data, refresh = 0)
print(M12a) # We see 3.9 under sigma indeed
# See the range of x
summary(hibbs$growth) # roughly 0 to 4%
# Let's write down what we know. We're given the linear relationship, and we know what the residual standard deviation should be:
intercept = 30
slope = 10
residual_sd = 3.9
# Now, let's generate some x-values in the same range as the real data (0 to 4 roughly), since the question asks for 'same range of x'
x_values <- seq(0, 4, length.out = 20)  # x ranging from 0 to 4%, getting 100 points
# Now, we can calculate some y values based on the line we're given (we will add the error term shortly)
y_values_line <- intercept + slope * x_values
# Generate hypothetical data with the same residual standard deviation
# We can do this by adding normally distributed random errors with standard deviation of 3.9
set.seed(240)  # for reproducibility
y_values_data <- y_values_line + rnorm(length(x_values), mean = 0, sd = residual_sd)
# Create dataframe for ggplot
data <- data.frame(
x = x_values,            # our x-values between 0 and 4
y_line = y_values_line,  # y-data with line
y_data = y_values_data   # y-data with error
)
# Now, let's plot
p <- ggplot(data, aes(x = x)) +
geom_point(aes(y = y_data), alpha = 0.6, color = 'blue') +  # Plotting the data points
geom_line(aes(y = y_line), color = 'black') +  # Plotting the regression line
labs(
x = 'Average recent growth in personal income (%)',
y = "Incumbent party's vote share",
title = 'Hypothetical data and fitted line',
subtitle = 'Fitted line: y = 30 + 10x'
) +
theme_minimal() +
theme(legend.position = "none") +
geom_smooth(aes(y = y_data), method = "lm", se = FALSE, color = "black")  # Ensure the correct y aesthetic is used
# Display the plot
p
# Fit a model for fun to see
M12a <- stan_glm(y_data ~ x, data = data, refresh = 0)
print(M12a) # We see 3.9 under sigma indeed
set.seed(2003) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# Specifying my stuff
n <- 2000 # Number of points
mean <- 50 # Specified mean
sd <- 10 # Specified standard deviation
data <- rnorm(n, mean, sd) # Generate random data
# Making a plot
ggplot(data.frame(x = data), aes(x)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
geom_density(alpha = .2, fill = "#FF6666") +
labs(title = "Histogram of Simulated Data", x = "Value", y = "Density")
# See the range of x
summary(hibbs$growth) # roughly 0 to 4%
# Let's write down what we know. We're given the linear relationship, and we know what the residual standard deviation should be:
intercept = 30
slope = 10
residual_sd = 3.9
# Now, let's generate some x-values in the same range as the real data (0 to 4 roughly), since the question asks for 'same range of x'
x_values <- seq(0, 4, length.out = 2000)  # x ranging from 0 to 4%, getting 100 points
# Now, we can calculate some y values based on the line we're given (we will add the error term shortly)
y_values_line <- intercept + slope * x_values
# Generate hypothetical data with the same residual standard deviation
# We can do this by adding normally distributed random errors with standard deviation of 3.9
set.seed(240)  # for reproducibility
y_values_data <- y_values_line + rnorm(length(x_values), mean = 0, sd = residual_sd)
# Create dataframe for ggplot
data <- data.frame(
x = x_values,            # our x-values between 0 and 4
y_line = y_values_line,  # y-data with line
y_data = y_values_data   # y-data with error
)
# Now, let's plot
p <- ggplot(data, aes(x = x)) +
geom_point(aes(y = y_data), alpha = 0.6, color = 'blue') +  # Plotting the data points
geom_line(aes(y = y_line), color = 'black') +  # Plotting the regression line
labs(
x = 'Average recent growth in personal income (%)',
y = "Incumbent party's vote share",
title = 'Hypothetical data and fitted line',
subtitle = 'Fitted line: y = 30 + 10x'
) +
theme_minimal() +
theme(legend.position = "none") +
geom_smooth(aes(y = y_data), method = "lm", se = FALSE, color = "black")  # Ensure the correct y aesthetic is used
# Display the plot
p
# Fit a model for fun to see
M12a <- stan_glm(y_data ~ x, data = data, refresh = 0)
print(M12a) # We see 3.9 under sigma indeed
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/mie/OneDrive/Skole/Methods 2 The General Linear Model/Methods2_resources/classes")
# Make sure this guy is installed/updated (if you've alreadygot rstanarm installed, you just need to load it in using either library() or p_load() as below)
#install.packages("rstanarm")
library(rstanarm)
# Load the rest
library(pacman)
pacman::p_load(tidyverse,
ggpubr,
ggplot2,
stringr) # this time I'm just giving you the code
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
# Make scatterplot
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Add a fitted line to the graph
abline(coef(M1), col="gray") # needs to be run with the plot() code above - running the whole chunk is the easiest way
# Display the fitted model
print(M1)
# Basic plot with ggplot2
ggplot(hibbs, aes(x = growth, y = vote)) +
geom_point() +  # Add points
labs(
x = "Average recent growth in personal income",
y = "Incumbent party's vote share",
title = "Relationship between Income Growth and Vote Share",
subtitle = "Data from Hibbs Dataset"
) +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_smooth(method = "lm", se = FALSE, color = "blue")  # Add a linear regression line
set.seed(2003) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# your code here  -  stimulating my data
n <- 20
mean <- 7
sd <- 3
myNormalData <- rnorm(n, mean, sd)
# my histogram of my normalised data
hist(myNormalData)
# find the mean and the sd by calculating them with their respective functions
mean(myNormalData)  # gives a mean of 7.86, which differs by 0.86 from what the value I gave for the stimulation of the data
sd(myNormalData)  # gives a sd of 2.77, which differs by 0.23 from what the value I gave for the stimulation of the data
# 0) see the range of x
summary(hibbs$growth) # roughly 0 to 4%
# 1) saves the coefficients
intercept <- 30
slope <- 10
# 2) makes the x-values of the range
x <- seq(0, 4, length.out = 20) # length.out = 20 makes 20 values, which matches the
# 3) calculates y - still without the error, and therefore it's y for the straight regression line
y_noError <- slope * x + intercept
# 4) add random error to the line above
set.seed(240)  # for reproducibility
normalisedError <- rnorm(length(x), 0, 3.9) # make normally distributed random errors w. sd of 3.9
# length(x) is for generating the same number of values as there is for x AND 0 is the mean
y_withError <- slope * x + intercept + normalisedError # as as y_withError <- y_noError + normalisedError
# 5) plotting by putting the x- and y-values in a dataframe to prepare for plotting w. ggplot
preparedData <- data.frame(xValues = x, yValues = y_withError)
preparedData # printing of dataframe
# 6) plotting it
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x, y = y_withError)) +
geom_point() +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_smooth(method = "lm", se = FALSE, color = "orange")  # Add a linear regression line
# 7) fit and review regression model: fit a linear regression model to the generated data by stan_glm() + see how closely the estimated parameters match the ones used to generate the data
# fitting a linear regression model to the generated data
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData)
plot(preparedData$x, preparedData$y_withError)
abline(coef(linearRegressionModel), col="purple")
print(linearRegressionModel)
# this could also be easily done with M12a <- stan_glm(y_withError ~ x, data = preparedData, refresh = 0)
stan_glm(y_withError ~ x, data = preparedData, refresh = 0)
# looks at how closely the estimated parameters match the ones used to generate the data
# the estimated data:
# the generated data:
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Add a fitted line to the graph
abline(coef(M1), col="gray") # needs to be run with the plot() code above - running the whole chunk is the easiest way
# Display the fitted model
print(M1)
#### 7) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
preparedData <- data.frame(xValues = x, yModel = y_noError, yData = y_withError)
preparedData # printing of dataframe
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_line(aes(y = yModel)) +# Add line of model
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_smooth(method = "lm", se = FALSE, color = "orange")  # Add a linear regression line
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_smooth(method = "lm", se = FALSE, color = "orange")+  # Add a linear regression line
geom_line(aes(y = yModel)) # Add line of model
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_line(aes(y = yModel), color = "orange") # Add line of model
set.seed(2003) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# your code here  -  stimulating my data
n <- 2000
mean <- 7
sd <- 3
myNormalData <- rnorm(n, mean, sd)
# 0) see the range of x
summary(hibbs$growth) # roughly 0 to 4%
# 1) saves the coefficients
intercept <- 30
slope <- 10
# 2) makes the x-values of the range
x <- seq(0, 4, length.out = 2000) # length.out = 20 makes 20 values, which matches the
# 3) calculates y - still without the error, and therefore it's y for the straight regression line
y_noError <- slope * x + intercept
# 4) add random error to the line above
set.seed(240)  # for reproducibility
normalisedError <- rnorm(length(x), 0, 3.9) # make normally distributed random errors w. sd of 3.9
# length(x) is for generating the same number of values as there is for x AND 0 is the mean
y_withError <- slope * x + intercept + normalisedError # as as y_withError <- y_noError + normalisedError
# 5) plotting by putting the x- and y-values in a dataframe to prepare for plotting w. ggplot
preparedData <- data.frame(xValues = x, yModel = y_noError, yData = y_withError)
preparedData # printing of dataframe
# 6) plotting it
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_line(aes(y = yModel), color = "orange") # Add line of model
# 7) fit and review regression model: fit a linear regression model to the generated data by stan_glm() + see how closely the estimated parameters match the ones used to generate the data
# fitting a linear regression model to the generated data
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData)
plot(preparedData$x, preparedData$y_withError)
abline(coef(linearRegressionModel), col="purple")
print(linearRegressionModel)
# this could also be easily done with M12a <- stan_glm(y_withError ~ x, data = preparedData, refresh = 0)
stan_glm(y_withError ~ x, data = preparedData, refresh = 0)
# looks at how closely the estimated parameters match the ones used to generate the data
# the estimated data:
# the generated data:
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Add a fitted line to the graph
abline(coef(M1), col="gray") # needs to be run with the plot() code above - running the whole chunk is the easiest way
# Display the fitted model
print(M1)
#### 7) Optional: Fit and review a regression model: As an additional step, you can fit a linear regression model to the generated data using stan_glm() or any other fitting function to see how closely the estimated parameters match the ones used to generate the data.
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_line(aes(y = yModel), color = "orange") # Add line of model
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_line(aes(y = yModel), color = "orange", size = 2) # Add line of model
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData)
plot(preparedData$x, preparedData$y_withError)
abline(coef(linearRegressionModel), col="purple")
print(linearRegressionModel)
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData)
plot(preparedData$x, preparedData$y_withError)
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData)
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData)
plot(preparedData$x, preparedData$y_withError)
abline(coef(linearRegressionModel), col="purple")
print(linearRegressionModel)
stan_glm(y_withError ~ x, data=preparedData)
abline(coef(linearRegressionModel), col="purple")
print(linearRegressionModel)
x <- seq(0, 4, length.out = 2000) # length.out = 20 makes 20 values, which matches the
y_noError <- slope * x + intercept
# 2) makes the x-values of the range
x <- seq(0, 4, length.out = 2000) # length.out = 20 makes 20 values, which matches the
# 3) calculates y - still without the error, and therefore it's y for the straight regression line
y_noError <- slope * x + intercept
# 4) add random error to the line above
set.seed(240)  # for reproducibility
normalisedError <- rnorm(length(x), 0, 10) # make normally distributed random errors w. sd of 10 (NEW)
# length(x) is for generating the same n
y_withError <- slope * x + intercept + normalisedError # as as y_withError <- y_noError + normalisedError
# 5) plotting by putting the x- and y-values in a dataframe to prepare for plotting w. ggplot
preparedData <- data.frame(xValues = x, yModel = y_noError, yData = y_withError)
preparedData # printing of dataframe
# 6) plotting it
# Basic plot with ggplot2
ggplot(preparedData,aes(x = x)) +
geom_point(aes(y = yData)) +# Add points
labs(title = "my Data Plotted w. error",
x = "Average recent groth in personal income (%)",
y = "Incubent party's vote share") +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_line(aes(y = yModel), color = "orange", size = 2) # Add line of model
# 7) fit and review regression model: fit a linear regression model to the generated data by stan_glm() + see how closely the estimated parameters match the ones used to generate the data
# fitting a linear regression model to the generated data
linearRegressionModel <- stan_glm(y_withError ~ x, data=preparedData, refresh = 0)
plot(preparedData$x, preparedData$y_withError)
abline(coef(linearRegressionModel), col="purple")
print(linearRegressionModel)
# Get the data in (says in the book where it is)
allnames_clean <- read.csv("data/Names/data/allnames_clean.csv")
head(allnames_clean)
unique(allnames_clean$sex)  # checks all the different values in the sex column
allnames_clean_FEMALE <- filter(allnames_clean, sex = 'F')
allnames_clean_FEMALE <- filter(allnames_clean, sex == 'F')
unique(allnames_clean_FEMALE$sex)  # checks that there is only females in this new data frame
allnames_clean_FEMALE <- allnames_clean_FEMALE %>% mutate(lastLetter = str_sub(allnames_clean_FEMALE$name, -1)) # take the last letter of the names. str_sub(allnames_clean_FEMALE$name, -1)) makes a substring starting from the last character of each element in the name column
allnames_clean_FEMALE <- allnames_clean_FEMALE %>% mutate(lastLetter = str_sub(allnames_clean_FEMALE$name, -1))
# add these last letters as a new column in the data frame
allnames_clean_FEMALE <- allnames_clean_FEMALE %>% mutate(lastLetter = str_sub(allnames_clean_FEMALE$name, -1)) # take the last letter of the names. str_sub(allnames_clean_FEMALE$name, -1)) makes a substring starting from the last character of each element in the name column
# converts the column values to factors as it would then show the different ends names have
allnames_clean_FEMALE <- allnames_clean_FEMALE %>% mutate(lastLetter = as.factor(lastLetter))
class(allnames_clean_FEMALE$lastLetter)
colnames(allnames_clean_FEMALE)
allnames_clean_FEMALE
head(allnames_clean_FEMALE)
years <- grep("^X\\d{4}$", names(female_names), value = TRUE)
years <- grep("^X\\d{4}$", names(allnames_clean_FEMALE), value = TRUE)
# FROM SOLUTION: Now, for each letter, let's summarise number of those per year. summarise_at() uses the summary function on multiple columns of a df
sums <- allnames_clean_FEMALE %>% group_by(lastLetter) %>% summarise_at(years, sum, na.rm = TRUE)
freq2Percent(sums)
# Turning the frequencies of each name per year into percentages
freq2Percent <- function(x, na.rm = TRUE) (x/sum(x))*100
freq2Percent(sums)
# FROM SOLUTION: Now, for each letter, let's summarise number of those per year. summarise_at() uses the summary function on multiple columns of a df
sums <- allnames_clean_FEMALE %>% group_by(lastLetter) %>% summarise_at(years, sum, na.rm = TRUE)
sums
# FROM SOLUTION: here the function mutate_at() (like before) applies a function to multiple columns of a df, in this case that function is freq_to_perc - this is done for sums and years
percentage_names_f<- mutate_at(sums,
years,
freq_to_perc)
# FROM SOLUTION: here the function mutate_at() (like before) applies a function to multiple columns of a df, in this case that function is freq2Percent - this is done for sums and years
percentage_names_f<- mutate_at(sums,
years,
freq2Percent)
percentage_names_f
# FROM SOLUTION: Pivot longer because it's nicer - we want one row for each year with each letter.
# that is getting it from multiple columns to one line
long_df <- pivot_longer(percentage_names_f, cols = years, names_to = "Year", values_to = "number")
class(long_df$Year)
long_df$Year
long_df <- long_df %>% mutate(Year = as.factor(Year))
long_df <- long_df %>% mutate(Year = as.numeric(Year))
class(long_df$Year) # checks the class of year
long_df$Year
long_df$Year <- long_df$Year+1879
max(long_df$Year)
min(long_df$Year)
long_df$Year # checks how the data of year look
head(long_df$Year) # checks how the data of year look
# FROM SOLUTION:
long_df %>%
ggplot(aes(x = Year, y = number, col = lastLetter, group = lastLetter)) +
geom_line() +
labs(y = "Percentage of girls born with letter",
title = "Overview of % girls born with a specific last letter each year",
x = "Years") +
scale_x_continuous() +
theme(axis.text.x = element_text(angle = -45),
plot.title = element_text(face = "bold")) # Makes title bold
